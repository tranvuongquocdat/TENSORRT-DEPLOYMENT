{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102967424/102967424 [==============================] - 13s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#ONNX conversion and deployment\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "model = ResNet50(weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert from keras tensorflow to ONNX\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py:126: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2022-11-02 09:49:08,277 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2022-11-02 09:49:08,590 - INFO - Signatures found in model: [serving_default].\n",
      "2022-11-02 09:49:08,590 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2022-11-02 09:49:08,590 - INFO - Output names: ['dense_1']\n",
      "WARNING:tensorflow:From c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf2onnx\\tf_loader.py:715: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-11-02 09:49:08,647 - WARNING - From c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf2onnx\\tf_loader.py:715: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-11-02 09:49:08,674 - INFO - Using tensorflow=2.10.0, onnx=1.12.0, tf2onnx=1.12.1/b6d590\n",
      "2022-11-02 09:49:08,674 - INFO - Using opset <onnx, 13>\n",
      "2022-11-02 09:49:08,688 - INFO - Computed 0 values for constant folding\n",
      "2022-11-02 09:49:08,705 - INFO - Optimizing ONNX model\n",
      "2022-11-02 09:49:08,761 - INFO - After optimization: Cast -1 (1->0), Identity -2 (2->0), Transpose -8 (10->2)\n",
      "2022-11-02 09:49:08,764 - INFO - \n",
      "2022-11-02 09:49:08,764 - INFO - Successfully converted TensorFlow model my_model to ONNX\n",
      "2022-11-02 09:49:08,764 - INFO - Model inputs: ['conv2d_input']\n",
      "2022-11-02 09:49:08,764 - INFO - Model outputs: ['dense_1']\n",
      "2022-11-02 09:49:08,764 - INFO - ONNX model is saved at traffic_sign_temp.onnx\n"
     ]
    }
   ],
   "source": [
    "#convert Resnet50 from h5 to onnx_model\n",
    "import onnx\n",
    "import tf2onnx\n",
    "\n",
    "model.save('my_model')\n",
    "!python -m tf2onnx.convert --saved-model my_model --output traffic_sign_temp.onnx\n",
    "onnx_model = onnx.load_model('traffic_sign_temp.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set an explicit batch size in the ONNX file\n",
    "BATCH_SIZE = 64\n",
    "inputs = onnx_model.graph.input\n",
    "for input in inputs:\n",
    "    dim1 = input.type.tensor_type.shape.dim[0]\n",
    "    dim1.dim_value = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the ONNX file\n",
    "model_name = \"traffic_sign.onnx\"\n",
    "onnx.save_model(onnx_model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to C:\\Users\\PC/.cache\\torch\\hub\\checkpoints\\resnext50_32x4d-7cdf4587.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dc88e869cb47c1bdccc5f108f63f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/95.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#convert pytorch to ONNX\n",
    "\n",
    "#import resnet model\n",
    "import torchvision.models as models\n",
    "\n",
    "resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n",
    "\n",
    "#save ONNX file from pytorch\n",
    "import torch\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "dummy_input=torch.randn(BATCH_SIZE, 3, 224, 224)\n",
    "\n",
    "#Save ONNX file\n",
    "import torch.onnx\n",
    "torch.onnx.export(resnext50_32x4d, dummy_input, \"resnet50_onnx_model(from Pytorch).onnx\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert from pytorch to ONNX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e593ac106456af50ce7af38f9671c411b49d6cd90f9b885e167f0f594e09038c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
